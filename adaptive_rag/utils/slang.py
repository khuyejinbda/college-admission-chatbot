import re
import json
import requests
import openai
from dotenv import load_dotenv
import os

# API í‚¤ ì •ë³´ ë¡œë“œ
load_dotenv()

# API í‚¤ ì½ì–´ì˜¤ê¸°
openai_api_key = os.environ.get('OPENAI_API_KEY')

def slangword_translate(text: str, slang_dict: dict) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ìŠ¬ë­(ì¤„ì„ë§)ì„ ëª¨ë‘ '(ìŠ¬ë­/ì •ì‹í‘œí˜„)' í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

    ì²˜ë¦¬ ê³¼ì •:
      1) ìŠ¬ë­ í‚¤ë¥¼ ê¸¸ì´ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê¸´ í‚¤ë¶€í„° ë§¤ì¹­
      2) íŠ¹ìˆ˜ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•˜ì—¬ ì•ˆì „í•œ ì •ê·œì‹ íŒ¨í„´ ìƒì„±
      3) í•œ ë²ˆì˜ re.subë¡œ ëª¨ë“  ë§¤ì¹­ëœ ìŠ¬ë­ ì¹˜í™˜

    Args:
        text (str): ì›ë³¸ í…ìŠ¤íŠ¸
        slang_dict (dict): {ìŠ¬ë­: ì •ì‹í‘œí˜„} ë§¤í•‘ ì‚¬ì „
    Returns:
        str: '(ìŠ¬ë­/ì •ì‹í‘œí˜„)' í˜•íƒœë¡œ ë³€í™˜ëœ ë¬¸ìì—´
    """
    # 2-1) í‚¤ë“¤ì„ ê¸¸ì´ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ í‚¤ê°€ ë¨¼ì € ë§¤ì¹­ë˜ë„ë¡)
    sorted_slangs = sorted(slang_dict.keys(), key=len, reverse=True)
    escaped_keys  = [re.escape(s) for s in sorted_slangs]
    combined_re = re.compile('(' + '|'.join(escaped_keys) + ')')

    # 2-2) ì¹˜í™˜ ì½œë°±: ë§¤ì¹­ëœ í‚¤(found) â†’ "(found/formal)" í˜•íƒœë¡œ ë¦¬í„´
    def _repl(m: re.Match) -> str:
        found = m.group(1)         # ì¤„ì„ë§
        formal = slang_dict[found] # ì •ì‹ í‘œí˜„
        return f"({found}/{formal})"

    # 2-3) í•œ ë²ˆë§Œ re.sub() ìˆ˜í–‰
    return combined_re.sub(_repl, text)


def select_contextual_word(input_translate: str) -> str:
    """
    ì¤‘ê°„ ë¬¸ìì—´ ë‚´ ì—¬ëŸ¬ '(ìŠ¬ë­/ì •ì‹)' íŒ¨í„´ ê°ê°ì— ëŒ€í•´ GPT-4o-mini ëª¨ë¸ì„ í˜¸ì¶œ,
    ë¬¸ë§¥ì— ë§ëŠ” í‘œí˜„ì„ ì„ íƒí•˜ì—¬ ê´„í˜¸ì™€ ìŠ¬ë˜ì‹œë¥¼ ì œê±°í•œ ìµœì¢… ë¬¸ì¥ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

    Args:
        input_translate (str): slangword_translate ì¶œë ¥ ë¬¸ìì—´
    Returns:
        str: ê´„í˜¸Â·ìŠ¬ë˜ì‹œ ì œê±° í›„ ì™„ì„±ëœ ë¬¸ì¥
    """
    system_prompt = (
        "ë‹¹ì‹ ì€ ì¤„ì„ë§ê³¼ ì •ì‹í‘œí˜„ì„ êµ¬ë¶„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ë¬¸ì¥ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ ê´„í˜¸ ì•ˆì— ìŠ¬ë˜ì‹œ(/)ë¡œ ë³‘ê¸°ëœ ë‘ ì–´êµ¬(phrase)ê°€ ìˆìŠµë‹ˆë‹¤.\n"
        "ê° ê´„í˜¸ë§ˆë‹¤ ë‘ ì–´êµ¬ ì¤‘ ë¬¸ë§¥ìƒ ë” ì ì ˆí•œ ì–´êµ¬ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬, \n"
        "ì „ì²´ ë¬¸ì¥ì„ ì™„ì„±í•œ í›„ ë°˜í™˜í•˜ì„¸ìš”.\n"
        "ë°˜ë“œì‹œ ê´„í˜¸ì™€ ìŠ¬ë˜ì‹œë¥¼ ì œê±°í•˜ê³ , ì„ íƒëœ ì–´êµ¬ ê°ê°ìœ¼ë¡œë§Œ êµì²´í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        "ê·¸ ì™¸ì˜ ì›ë˜ í…ìŠ¤íŠ¸(ì–´ë¯¸, ì¡°ì‚¬, ë„ì–´ì“°ê¸° ë“±)ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”."
        "ë‹¹ì‹ ì€ ì˜¤ë¡œì§€, ë¬¸ë§¥ì— ë§ëŠ” í‘œí˜„ì„ ì„ íƒí•˜ëŠ” ì—­í• ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n"
    )
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system",  "content": system_prompt},
            {"role": "user",    "content": input_translate}
        ]
    )
    return response.choices[0].message.content.strip()

def strip_slang_markers(intermediate: str) -> str:
    """
    '(ìŠ¬ë­/ì •ì‹)' í˜•íƒœì˜ ëª¨ë“  íŒ¨í„´ì„ ì •ì‹í‘œí˜„ë§Œ ë‚¨ê¸°ê³  ì œê±°
    ë‚˜ë¨¸ì§€ ë¬¸ìì—´(êµ¬ë‘ì  ë° ê³µë°± í¬í•¨)ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³´ì¡´

    Args:
        intermediate (str): '(ìŠ¬ë­/ì •ì‹)'ì´ í¬í•¨ëœ ì¤‘ê°„ ë¬¸ìì—´
    Returns:
        str: ì •ì‹í‘œí˜„ë§Œ ë‚¨ì€ ìµœì¢… ë¬¸ìì—´
    """
    pattern = re.compile(r"\(([^/]+)/([^\)]+)\)")
    result_parts = []
    last_end = 0

    for m in pattern.finditer(intermediate):
        result_parts.append(intermediate[last_end:m.start()])
        result_parts.append(m.group(2))
        last_end = m.end()

    result_parts.append(intermediate[last_end:])
    return "".join(result_parts)


def replace_slang_word(text: str, slang_dict: dict) -> dict:
    """
    í…ìŠ¤íŠ¸ì— ìŠ¬ë­ì´ í¬í•¨ëœ ê²½ìš° ì•„ë˜ ë‹¨ê³„ë¡œ ë³€í™˜:
      1) slangword_translate â†’ '(ìŠ¬ë­/ì •ì‹)' í˜•íƒœ ìƒì„±
      2) ì²« '(.../...)'ì˜ ì •ì‹í‘œí˜„ì— ì‰¼í‘œê°€ ìˆìœ¼ë©´ strip_slang_markers ì‚¬ìš©
      3) ì‰¼í‘œ ì—†ìœ¼ë©´ select_contextual_wordë¡œ GPT í˜¸ì¶œ
    ìŠ¬ë­ì´ ì—†ìœ¼ë©´ ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜

    Args:
        text (str): ì›ë³¸ í…ìŠ¤íŠ¸
        slang_dict (dict): ìŠ¬ë­-ì •ì‹ ë§¤í•‘ ì‚¬ì „
    Returns:
        dict: {'question': ìµœì¢… ì²˜ë¦¬ëœ ë¬¸ìì—´}
    """

    intermediate = slangword_translate(text, slang_dict)

    if intermediate == text:
        return {"question": text}  # ğŸ¯ ì¹˜í™˜ ì—†ìœ¼ë©´ GPT í˜¸ì¶œí•˜ì§€ ì•ŠìŒ

    m = re.search(r"\(([^/]+)/([^\)]+)\)", intermediate)
    if m:
        formal_part = m.group(2).strip()
        if "," in formal_part:
            result_text = strip_slang_markers(intermediate)
            return {"question": result_text}
    final_text = select_contextual_word(intermediate)
    return {"question": final_text}

